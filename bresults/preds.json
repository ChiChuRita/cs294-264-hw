{
  "django__django-10973": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-10973",
    "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..5b311742a6 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -2,17 +2,9 @@ import os\n import signal\n import subprocess\n \n-from django.core.files.temp import NamedTemporaryFile\n from django.db.backends.base.client import BaseDatabaseClient\n \n \n-def _escape_pgpass(txt):\n-    \"\"\"\n-    Escape a fragment of a PostgreSQL .pgpass file.\n-    \"\"\"\n-    return txt.replace('\\\\', '\\\\\\\\').replace(':', '\\\\:')\n-\n-\n class DatabaseClient(BaseDatabaseClient):\n     executable_name = 'psql'\n \n@@ -34,38 +26,21 @@ class DatabaseClient(BaseDatabaseClient):\n             args += ['-p', str(port)]\n         args += [dbname]\n \n-        temp_pgpass = None\n+        env = None\n         sigint_handler = signal.getsignal(signal.SIGINT)\n         try:\n             if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n-                try:\n-                    print(\n-                        _escape_pgpass(host) or '*',\n-                        str(port) or '*',\n-                        _escape_pgpass(dbname) or '*',\n-                        _escape_pgpass(user) or '*',\n-                        _escape_pgpass(passwd),\n-                        file=temp_pgpass,\n-                        sep=':',\n-                        flush=True,\n-                    )\n-                    os.environ['PGPASSFILE'] = temp_pgpass.name\n-                except UnicodeEncodeError:\n-                    # If the current locale can't encode the data, let the\n-                    # user input the password manually.\n-                    pass\n+                # Pass the password to psql via the PGPASSWORD environment\n+                # variable for simplicity and reliability.\n+                env = os.environ.copy()\n+                env['PGPASSWORD'] = passwd\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+            # Use subprocess.run to allow passing a custom environment.\n+            subprocess.run(args, check=True, env=env)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)\n-            if temp_pgpass:\n-                temp_pgpass.close()\n-                if 'PGPASSFILE' in os.environ:  # unit tests need cleanup\n-                    del os.environ['PGPASSFILE']\n \n     def runshell(self):\n-        DatabaseClient.runshell_db(self.connection.get_connection_params())\n+        DatabaseClient.runshell_db(self.connection.get_connection_params())\n\\ No newline at end of file\n"
  },
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..799a79cf6d 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -271,14 +271,15 @@ class Collector:\n         # number of objects deleted for each model label\n         deleted_counter = Counter()\n \n-        # Optimize for the case with a single obj and no dependencies\n+# Optimize for the case with a single obj and no dependencies\n         if len(self.data) == 1 and len(instances) == 1:\n             instance = list(instances)[0]\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                # Clear the primary key on the instance to reflect that it's been deleted.\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n-\n         with transaction.atomic(using=self.using, savepoint=False):\n             # send pre_delete signals\n             for model, obj in self.instances_with_model():\n"
  },
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..d7e0bf3973 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -173,9 +173,21 @@ class MigrationWriter:\n         else:\n             imports.add(\"from django.db import migrations\")\n \n-        # Sort imports by the package / module to be imported (the part after\n+# Sort imports by the package / module to be imported (the part after\n         # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n-        sorted_imports = sorted(imports, key=lambda i: i.split()[1])\n+        def _import_key(i):\n+            parts = i.split()\n+            if parts[0] == \"import\":\n+                module = parts[1]\n+                kind = 0\n+            elif parts[0] == \"from\":\n+                module = parts[1]\n+                kind = 1\n+            else:\n+                module = i\n+                kind = 2\n+            return (module, kind, i)\n+        sorted_imports = sorted(imports, key=_import_key)\n         items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n         if migration_imports:\n             items[\"imports\"] += (\n"
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 41387886c0..26df20d921 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -2302,9 +2302,16 @@ A list of fallback secret keys for a particular Django installation. These are\n used to allow rotation of the ``SECRET_KEY``.\n \n In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the\n-previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Then remove the\n-old values from the end of the ``SECRET_KEY_FALLBACKS`` when you are ready to\n-expire the sessions, password reset tokens, and so on, that make use of them.\n+previous value to the beginning of ``SECRET_KEY_FALLBACKS``.\n+\n+Note that not all uses of the secret key consult ``SECRET_KEY_FALLBACKS``.\n+Only signing operations which explicitly check fallback keys (for example, the\n+cookie signer and the password reset token generator) will accept fallback\n+keys. Session authentication hashes (used by\n+``AbstractBaseUser.get_session_auth_hash()``) use the current ``SECRET_KEY``\n+directly and do not consult ``SECRET_KEY_FALLBACKS``. Rotating ``SECRET_KEY``\n+will therefore invalidate existing sessions even if the old key is present in\n+``SECRET_KEY_FALLBACKS``.\n \n .. note::\n \n"
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..4a1e43f0ec 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -17,7 +17,7 @@ from django.core.exceptions import ImproperlyConfigured\n from django.core.handlers.wsgi import LimitedStream\n from django.core.wsgi import get_wsgi_application\n from django.utils.module_loading import import_string\n-\n+from django.db import connections\n __all__ = ('WSGIServer', 'WSGIRequestHandler')\n \n logger = logging.getLogger('django.server')\n@@ -113,9 +113,17 @@ class ServerHandler(simple_server.ServerHandler):\n         if self.headers.get('Connection') == 'close':\n             self.request_handler.close_connection = True\n \n-    def close(self):\n+def close(self):\n         self.get_stdin()._read_limited()\n-        super().close()\n+        try:\n+            super().close()\n+        finally:\n+            # Ensure any DB connections opened during the request are closed.\n+            # Protect against any errors during close to avoid breaking request cleanup.\n+            try:\n+                connections.close_all()\n+            except Exception:\n+                pass\n \n \n class WSGIRequestHandler(simple_server.WSGIRequestHandler):\n"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..47220a896c 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -27,6 +27,15 @@ class ContextMixin:\n         kwargs.setdefault('view', self)\n         if self.extra_context is not None:\n             kwargs.update(self.extra_context)\n+        # Resolve any SimpleLazyObject-wrapped values (e.g. the deprecated\n+        # TemplateView URL kwargs wrapper) so that consumers that expect\n+        # concrete values (such as ORM filters) continue to work.\n+        for key, value in list(kwargs.items()):\n+            if isinstance(value, SimpleLazyObject):\n+                # Trigger evaluation of the lazy object and replace it with\n+                # the actual wrapped value.\n+                getattr(value, '__class__')\n+                kwargs[key] = value._wrapped\n         return kwargs\n \n \n"
  },
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex cd232e6..ee4aa38 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -391,7 +391,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         \"\"\"Prepares the given HTTP headers.\"\"\"\n \n         if headers:\n-            self.headers = CaseInsensitiveDict((to_native_string(name), value) for name, value in headers.items())\n+            self.headers = CaseInsensitiveDict((to_native_string(name), value) for name, value in headers.items() if value is not None)\n         else:\n             self.headers = CaseInsensitiveDict()\n \n"
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..ddc051cc6c 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -367,110 +367,34 @@ class BaseModelForm(BaseForm):\n             if (field == NON_FIELD_ERRORS and opts.error_messages and\n                     NON_FIELD_ERRORS in opts.error_messages):\n                 error_messages = opts.error_messages[NON_FIELD_ERRORS]\n-            elif field in self.fields:\n-                error_messages = self.fields[field].error_messages\n-            else:\n-                continue\n-\n-            for message in messages:\n-                if (isinstance(message, ValidationError) and\n-                        message.code in error_messages):\n-                    message.message = error_messages[message.code]\n-\n-        self.add_error(None, errors)\n-\n-    def _post_clean(self):\n-        opts = self._meta\n-\n-        exclude = self._get_validation_exclusions()\n-\n-        # Foreign Keys being used to represent inline relationships\n-        # are excluded from basic field value validation. This is for two\n-        # reasons: firstly, the value may not be supplied (#12507; the\n-        # case of providing new values to the admin); secondly the\n-        # object being referred to may not yet fully exist (#12749).\n-        # However, these fields *must* be included in uniqueness checks,\n-        # so this can't be part of _get_validation_exclusions().\n-        for name, field in self.fields.items():\n-            if isinstance(field, InlineForeignKeyField):\n-                exclude.append(name)\n-\n-        try:\n-            self.instance = construct_instance(self, self.instance, opts.fields, opts.exclude)\n-        except ValidationError as e:\n-            self._update_errors(e)\n-\n-        try:\n-            self.instance.full_clean(exclude=exclude, validate_unique=False)\n-        except ValidationError as e:\n-            self._update_errors(e)\n-\n-        # Validate uniqueness if needed.\n-        if self._validate_unique:\n-            self.validate_unique()\n-\n-    def validate_unique(self):\n-        \"\"\"\n-        Call the instance's validate_unique() method and update the form's\n-        validation errors if any were raised.\n-        \"\"\"\n-        exclude = self._get_validation_exclusions()\n-        try:\n-            self.instance.validate_unique(exclude=exclude)\n-        except ValidationError as e:\n-            self._update_errors(e)\n-\n-    def _save_m2m(self):\n-        \"\"\"\n-        Save the many-to-many fields and generic relations for this form.\n-        \"\"\"\n-        cleaned_data = self.cleaned_data\n-        exclude = self._meta.exclude\n-        fields = self._meta.fields\n-        opts = self.instance._meta\n-        # Note that for historical reasons we want to include also\n-        # private_fields here. (GenericRelation was previously a fake\n-        # m2m field).\n-        for f in chain(opts.many_to_many, opts.private_fields):\n-            if not hasattr(f, 'save_form_data'):\n-                continue\n-            if fields and f.name not in fields:\n-                continue\n-            if exclude and f.name in exclude:\n-                continue\n-            if f.name in cleaned_data:\n-                f.save_form_data(self.instance, cleaned_data[f.name])\n-\n-    def save(self, commit=True):\n-        \"\"\"\n-        Save this form's self.instance object if commit=True. Otherwise, add\n-        a save_m2m() method to the form which can be called after the instance\n-        is saved manually at a later time. Return the model instance.\n-        \"\"\"\n-        if self.errors:\n-            raise ValueError(\n-                \"The %s could not be %s because the data didn't validate.\" % (\n-                    self.instance._meta.object_name,\n-                    'created' if self.instance._state.adding else 'changed',\n-                )\n-            )\n-        if commit:\n-            # If committing, save the instance and the m2m data immediately.\n-            self.instance.save()\n-            self._save_m2m()\n+def __init__(self, queryset, *, empty_label=\"---------\",\n+                 required=True, widget=None, label=None, initial=None,\n+                 help_text='', to_field_name=None, limit_choices_to=None,\n+                 **kwargs):\n+        # If the field is required but an initial value is provided, there's\n+        # no need for an empty choice.\n+        if required and (initial is not None):\n+            self.empty_label = None\n         else:\n-            # If not committing, add a method to the form to allow deferred\n-            # saving of m2m data.\n-            self.save_m2m = self._save_m2m\n-        return self.instance\n-\n-    save.alters_data = True\n-\n-\n-class ModelForm(BaseModelForm, metaclass=ModelFormMetaclass):\n-    pass\n-\n+            # RadioSelect widgets have an inherent \"no selection\" state, so\n+            # presenting a blank choice (e.g. \"---------\") is misleading for\n+            # required model fields. Detect radio widgets (class or instance)\n+            # by checking their input_type and avoid adding an empty_label.\n+            is_radio_widget = widget is not None and getattr(widget, 'input_type', None) == 'radio'\n+            if required and is_radio_widget:\n+                self.empty_label = None\n+            else:\n+                self.empty_label = empty_label\n \n+        # Call Field instead of ChoiceField __init__() because we don't need\n+        # ChoiceField.__init__().\n+        Field.__init__(\n+            self, required=required, widget=widget, label=label,\n+            initial=initial, help_text=help_text, **kwargs\n+        )\n+        self.queryset = queryset\n+        self.limit_choices_to = limit_choices_to   # limit the queryset later.\n+        self.to_field_name = to_field_name\n def modelform_factory(model, form=ModelForm, fields=None, exclude=None,\n                       formfield_callback=None, widgets=None, localized_fields=None,\n                       labels=None, help_texts=None, error_messages=None,\n"
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..fd3520721 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -520,7 +520,7 @@ class InheritDocstrings(type):\n         u'Wiggle the thingamajig'\n     \"\"\"\n \n-    def __init__(cls, name, bases, dct):\n+def __init__(cls, name, bases, dct):\n         def is_public_member(key):\n             return (\n                 (key.startswith('__') and key.endswith('__')\n@@ -528,18 +528,50 @@ class InheritDocstrings(type):\n                 not key.startswith('_'))\n \n         for key, val in dct.items():\n-            if (inspect.isfunction(val) and\n-                is_public_member(key) and\n-                val.__doc__ is None):\n-                for base in cls.__mro__[1:]:\n-                    super_method = getattr(base, key, None)\n-                    if super_method is not None:\n-                        val.__doc__ = super_method.__doc__\n-                        break\n+            # We want to handle plain functions as well as common descriptor\n+            # wrappers such as @property, @classmethod and @staticmethod.\n+            if not is_public_member(key):\n+                continue\n+\n+            # Determine the actual function object whose __doc__ we may set\n+            target_func = None\n+            if inspect.isfunction(val):\n+                target_func = val\n+            elif isinstance(val, (staticmethod, classmethod)):\n+                target_func = val.__func__\n+            elif isinstance(val, property):\n+                # For properties, set the fget's docstring\n+                target_func = val.fget\n+\n+            # If we didn't find a target function (unsupported member), skip it\n+            if target_func is None:\n+                continue\n+\n+            # Only set the docstring if it is currently None\n+            if target_func.__doc__ is not None:\n+                continue\n+\n+            for base in cls.__mro__[1:]:\n+                super_method = getattr(base, key, None)\n+                if super_method is None:\n+                    continue\n+\n+                # Unwrap the superclass descriptor to find its docstring\n+                if isinstance(super_method, (staticmethod, classmethod)):\n+                    doc = super_method.__func__.__doc__\n+                elif isinstance(super_method, property):\n+                    doc = super_method.fget.__doc__\n+                else:\n+                    doc = super_method.__doc__\n+\n+                if doc is not None:\n+                    target_func.__doc__ = doc\n+                    break\n \n         super().__init__(name, bases, dct)\n \n \n+\n class OrderedDescriptor(metaclass=abc.ABCMeta):\n     \"\"\"\n     Base class for descriptors whose order in the class body should be\n"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "Support user-defined literal suffixes (UDLs) in C++ domain literal parsing (parse numeric, string, and char UDL suffixes)\n\nNo changes detected to generate a patch."
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..5705c821c2 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -175,7 +175,7 @@ def _collect_factor_and_dimension(self, expr):\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n"
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..95dfea40e4 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -183,43 +183,67 @@ def __abs__(self):\n         return Point.distance(origin, self)\n \n     def __add__(self, other):\n-        \"\"\"Add other to self by incrementing self's coordinates by\n-        those of other.\n-\n-        Notes\n-        =====\n-\n-        >>> from sympy.geometry.point import Point\n-\n-        When sequences of coordinates are passed to Point methods, they\n-        are converted to a Point internally. This __add__ method does\n-        not do that so if floating point values are used, a floating\n-        point result (in terms of SymPy Floats) will be returned.\n-\n-        >>> Point(1, 2) + (.1, .2)\n-        Point2D(1.1, 2.2)\n-\n-        If this is not desired, the `translate` method can be used or\n-        another Point can be added:\n-\n-        >>> Point(1, 2).translate(.1, .2)\n-        Point2D(11/10, 11/5)\n-        >>> Point(1, 2) + Point(.1, .2)\n-        Point2D(11/10, 11/5)\n-\n-        See Also\n-        ========\n-\n-        sympy.geometry.point.Point.translate\n-\n-        \"\"\"\n-        try:\n-            s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n-        except TypeError:\n-            raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n-\n-        coords = [simplify(a + b) for a, b in zip(s, o)]\n-        return Point(coords, evaluate=False)\n+            \"\"\"Add other to self by incrementing self's coordinates by\n+            those of other.\n+    \n+            Notes\n+            =====\n+    \n+            >>> from sympy.geometry.point import Point\n+    \n+            When sequences of coordinates are passed to Point methods, they\n+            are converted to a Point internally. This __add__ method does\n+            not do that so if floating point values are used, a floating\n+            point result (in terms of SymPy Floats) will be returned.\n+    \n+            >>> Point(1, 2) + (.1, .2)\n+            Point2D(1.1, 2.2)\n+    \n+            If this is not desired, the `translate` method can be used or\n+            another Point can be added:\n+    \n+            >>> Point(1, 2).translate(.1, .2)\n+            Point2D(11/10, 11/5)\n+            >>> Point(1, 2) + Point(.1, .2)\n+            Point2D(11/10, 11/5)\n+    \n+            See Also\n+            ========\n+    \n+            sympy.geometry.point.Point.translate\n+    \n+            \"\"\"\n+            try:\n+                s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n+            except TypeError:\n+                # Allow adding a scalar multiple of a Point, e.g. Point + (2*Point)\n+                # This handles cases where the left multiplication creates a Mul\n+                # such as sympify(2.0)*Point, which would otherwise result in a\n+                # TypeError when attempting to construct a Point from the Mul.\n+                from sympy.core.mul import Mul\n+                if isinstance(other, Mul):\n+                    # Find a single Point factor and treat everything else as the scalar\n+                    point_factor = None\n+                    scalar_factors = []\n+                    for a in other.args:\n+                        if isinstance(a, Point):\n+                            if point_factor is None:\n+                                point_factor = a\n+                            else:\n+                                # More than one Point factor: fall back to error\n+                                point_factor = None\n+                                break\n+                        else:\n+                            scalar_factors.append(a)\n+                    if point_factor is not None:\n+                        factor = Mul(*scalar_factors) if scalar_factors else S.One\n+                        s, o = Point._normalize_dimension(self, Point(point_factor, evaluate=False))\n+                        coords = [simplify(a + factor*b) for a, b in zip(s, o)]\n+                        return Point(coords, evaluate=False)\n+                raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+    \n+            coords = [simplify(a + b) for a, b in zip(s, o)]\n+            return Point(coords, evaluate=False)\n \n     def __contains__(self, item):\n         return item in self.args\n"
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..abe0b66c3 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -262,6 +262,11 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield\n     rep = outcome.get_result()\n     xfailed = item._store.get(xfailed_key, None)\n+    # Re-evaluate xfail marks here to account for markers added during test execution\n+    # (for example via request.node.add_marker in the test body).\n+    if xfailed is None:\n+        xfailed = evaluate_xfail_marks(item)\n+        item._store[xfailed_key] = xfailed\n     # unittest special case, see setting of unexpectedsuccess_key\n     if unexpectedsuccess_key in item._store and rep.when == \"call\":\n         reason = item._store[unexpectedsuccess_key]\n@@ -291,6 +296,8 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n+                rep.outcome = \"passed\"\n+                rep.wasxfail = xfailed.reason\n \n     if (\n         item._store.get(skipped_by_mark_key, True)\n"
  },
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 9c624d3..a5ed1ae 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -50,112 +50,115 @@ ITER_CHUNK_SIZE = 512\n \n \n class RequestEncodingMixin(object):\n-    @property\n-    def path_url(self):\n-        \"\"\"Build the path URL to use.\"\"\"\n-\n-        url = []\n-\n-        p = urlsplit(self.url)\n+        @property\n+        def path_url(self):\n+            \"\"\"Build the path URL to use.\"\"\"\n \n-        path = p.path\n-        if not path:\n-            path = '/'\n+            url = []\n \n-        url.append(path)\n+            p = urlsplit(self.url)\n \n-        query = p.query\n-        if query:\n-            url.append('?')\n-            url.append(query)\n+            path = p.path\n+            if not path:\n+                path = '/'\n \n-        return ''.join(url)\n+            url.append(path)\n \n-    @staticmethod\n-    def _encode_params(data):\n-        \"\"\"Encode parameters in a piece of data.\n-\n-        Will successfully encode parameters when passed as a dict or a list of\n-        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n-        if parameters are supplied as a dict.\n-        \"\"\"\n-\n-        if isinstance(data, (str, bytes)):\n-            return to_native_string(data)\n-        elif hasattr(data, 'read'):\n-            return data\n-        elif hasattr(data, '__iter__'):\n-            result = []\n-            for k, vs in to_key_val_list(data):\n-                if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):\n-                    vs = [vs]\n-                for v in vs:\n+            query = p.query\n+            if query:\n+                url.append('?')\n+                url.append(query)\n+\n+            return ''.join(url)\n+\n+        @staticmethod\n+        def _encode_params(data):\n+            \"\"\"Encode parameters in a piece of data.\n+\n+            Will successfully encode parameters when passed as a dict or a list of\n+            2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n+            if parameters are supplied as a dict.\n+            \"\"\"\n+\n+            if isinstance(data, str):\n+                return to_native_string(data)\n+            elif isinstance(data, bytes):\n+                return data\n+            elif hasattr(data, 'read'):\n+                return data\n+            elif hasattr(data, '__iter__'):\n+                result = []\n+                for k, vs in to_key_val_list(data):\n+                    if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):\n+                        vs = [vs]\n+                    for v in vs:\n+                        if v is not None:\n+                            result.append(\n+                                (k.encode('utf-8') if isinstance(k, str) else k,\n+                                 v.encode('utf-8') if isinstance(v, str) else v))\n+                return urlencode(result, doseq=True)\n+            else:\n+                return data\n+\n+        @staticmethod\n+        def _encode_files(files, data):\n+            \"\"\"Build the body for a multipart/form-data request.\n+\n+            Will successfully encode files when passed as a dict or a list of\n+            2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n+            if parameters are supplied as a dict.\n+\n+            \"\"\"\n+            if (not files):\n+                raise ValueError(\"Files must be provided.\")\n+            elif isinstance(data, basestring):\n+                raise ValueError(\"Data must not be a string.\")\n+\n+            new_fields = []\n+            fields = to_key_val_list(data or {})\n+            files = to_key_val_list(files or {})\n+\n+            for field, val in fields:\n+                if isinstance(val, basestring) or not hasattr(val, '__iter__'):\n+                    val = [val]\n+                for v in val:\n                     if v is not None:\n-                        result.append(\n-                            (k.encode('utf-8') if isinstance(k, str) else k,\n-                             v.encode('utf-8') if isinstance(v, str) else v))\n-            return urlencode(result, doseq=True)\n-        else:\n-            return data\n+                        # Don't call str() on bytestrings: in Py3 it all goes wrong.\n+                        if not isinstance(v, bytes):\n+                            v = str(v)\n \n-    @staticmethod\n-    def _encode_files(files, data):\n-        \"\"\"Build the body for a multipart/form-data request.\n+                        new_fields.append(\n+                            (field.decode('utf-8') if isinstance(field, bytes) else field,\n+                             v.encode('utf-8') if isinstance(v, str) else v))\n \n-        Will successfully encode files when passed as a dict or a list of\n-        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n-        if parameters are supplied as a dict.\n+            for (k, v) in files:\n+                # support for explicit filename\n+                ft = None\n+                fh = None\n+                if isinstance(v, (tuple, list)):\n+                    if len(v) == 2:\n+                        fn, fp = v\n+                    elif len(v) == 3:\n+                        fn, fp, ft = v\n+                    else:\n+                        fn, fp, ft, fh = v\n+                else:\n+                    fn = guess_filename(v) or k\n+                    fp = v\n \n-        \"\"\"\n-        if (not files):\n-            raise ValueError(\"Files must be provided.\")\n-        elif isinstance(data, basestring):\n-            raise ValueError(\"Data must not be a string.\")\n-\n-        new_fields = []\n-        fields = to_key_val_list(data or {})\n-        files = to_key_val_list(files or {})\n-\n-        for field, val in fields:\n-            if isinstance(val, basestring) or not hasattr(val, '__iter__'):\n-                val = [val]\n-            for v in val:\n-                if v is not None:\n-                    # Don't call str() on bytestrings: in Py3 it all goes wrong.\n-                    if not isinstance(v, bytes):\n-                        v = str(v)\n-\n-                    new_fields.append(\n-                        (field.decode('utf-8') if isinstance(field, bytes) else field,\n-                         v.encode('utf-8') if isinstance(v, str) else v))\n-\n-        for (k, v) in files:\n-            # support for explicit filename\n-            ft = None\n-            fh = None\n-            if isinstance(v, (tuple, list)):\n-                if len(v) == 2:\n-                    fn, fp = v\n-                elif len(v) == 3:\n-                    fn, fp, ft = v\n+                if isinstance(fp, (str, bytes, bytearray)):\n+                    fdata = fp\n                 else:\n-                    fn, fp, ft, fh = v\n-            else:\n-                fn = guess_filename(v) or k\n-                fp = v\n+                    fdata = fp.read()\n \n-            if isinstance(fp, (str, bytes, bytearray)):\n-                fdata = fp\n-            else:\n-                fdata = fp.read()\n+                rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)\n+                rf.make_multipart(content_type=ft)\n+                new_fields.append(rf)\n \n-            rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)\n-            rf.make_multipart(content_type=ft)\n-            new_fields.append(rf)\n+            body, content_type = encode_multipart_formdata(new_fields)\n \n-        body, content_type = encode_multipart_formdata(new_fields)\n+            return body, content_type\n \n-        return body, content_type\n \n \n class RequestHooksMixin(object):\n"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex d8cb75a5f..43efb4016 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -248,15 +248,7 @@ class GoogleDocstring:\n             lines.append(next(self._line_iter))\n         return lines\n \n-    def _consume_empty(self) -> List[str]:\n-        lines = []\n-        line = self._line_iter.peek()\n-        while self._line_iter.has_next() and not line:\n-            lines.append(next(self._line_iter))\n-            line = self._line_iter.peek()\n-        return lines\n-\n-    def _consume_field(self, parse_type: bool = True, prefer_type: bool = False\n+def _consume_field(self, parse_type: bool = True, prefer_type: bool = False\n                        ) -> Tuple[str, str, List[str]]:\n         line = next(self._line_iter)\n \n@@ -266,8 +258,18 @@ class GoogleDocstring:\n         if parse_type:\n             match = _google_typed_arg_regex.match(before)\n             if match:\n-                _name = match.group(1).strip()\n-                _type = match.group(2)\n+                # Handle both \"name(type)\" and \"type(...) name\" patterns.\n+                # For input like \"dict(str, str) opc_meta\", the regex will match\n+                # \"dict(str, str)\". If there's trailing text after the match,\n+                # treat the matched portion as the type and the trailing text\n+                # as the name.\n+                trailing = before[match.end():].strip()\n+                if trailing:\n+                    _type = before[:match.end()].strip()\n+                    _name = trailing\n+                else:\n+                    _name = match.group(1).strip()\n+                    _type = match.group(2)\n \n         _name = self._escape_args_and_kwargs(_name)\n \n"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..3b0ebccc47 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -49,13 +49,13 @@ class BaseHandler:\n                 middleware_is_async = False\n             else:\n                 middleware_is_async = middleware_can_async\n-            try:\n+try:\n                 # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n+                adapted_handler = self.adapt_method_mode(\n                     middleware_is_async, handler, handler_is_async,\n                     debug=settings.DEBUG, name='middleware %s' % middleware_path,\n                 )\n-                mw_instance = middleware(handler)\n+                mw_instance = middleware(adapted_handler)\n             except MiddlewareNotUsed as exc:\n                 if settings.DEBUG:\n                     if str(exc):\n"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "diff --git a/sphinx/util/typing.py b/sphinx/util/typing.py\nindex 87707d48f..78dbc0f03 100644\n--- a/sphinx/util/typing.py\n+++ b/sphinx/util/typing.py\n@@ -191,7 +191,7 @@ def _restify_py37(cls: Optional[Type]) -> str:\n         return text\n     elif isinstance(cls, typing._SpecialForm):\n         return ':py:obj:`~%s.%s`' % (cls.__module__, cls._name)\n-    elif hasattr(cls, '__qualname__'):\n+elif hasattr(cls, '__qualname__') and getattr(cls, '__qualname__', None):\n         if cls.__module__ == 'typing':\n             return ':py:class:`~%s.%s`' % (cls.__module__, cls.__qualname__)\n         else:\n"
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..abc175b1ab 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -91,7 +91,7 @@ class Command(BaseCommand):\n                 self.stderr.write(\"App '%s' could not be found. Is it in INSTALLED_APPS?\" % app_label)\n             sys.exit(2)\n \n-        # Load the current graph state. Pass in None for the connection so\n+# Load the current graph state. Pass in None for the connection so\n         # the loader doesn't try to resolve replaced migrations from DB.\n         loader = MigrationLoader(None, ignore_no_migrations=True)\n \n@@ -105,21 +105,10 @@ class Command(BaseCommand):\n                     # At least one model must be migrated to the database.\n                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n                     for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    for model in apps.get_app_config(app_label).get_models()\n             )):\n                 loader.check_consistent_history(connection)\n \n-        # Before anything else, see if there's conflicting apps and drop out\n-        # hard if there are any and they don't want to merge\n-        conflicts = loader.detect_conflicts()\n-\n-        # If app_labels is specified, filter out conflicting migrations for unspecified apps\n-        if app_labels:\n-            conflicts = {\n-                app_label: conflict for app_label, conflict in iteritems(conflicts)\n-                if app_label in app_labels\n-            }\n-\n         if conflicts and not self.merge:\n             name_str = \"; \".join(\n                 \"%s in %s\" % (\", \".join(names), app)\n"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "Agent reached maximum steps (100) without completing the task.\n\nNo changes detected to generate a patch."
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "Agent reached maximum steps (100) without completing the task.\n\nNo changes detected to generate a patch."
  }
}